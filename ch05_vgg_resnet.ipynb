{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%!\n",
    "kaggle datasets download -d tongpython/cat-and-dog\n",
    "unzip cat-and-dog.zip -d content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import cv2\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"training_set/training_set\"\n",
    "test_data_dir = \"test_set/test_set\"\n",
    "\n",
    "\n",
    "class CatsDogsDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        cats = glob(folder + \"/cats/*.jpg\")\n",
    "        dogs = glob(folder + \"/dogs/*.jpg\")\n",
    "        self.fpaths = cats[:500] + dogs[:500]\n",
    "        self.normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        from random import shuffle, seed\n",
    "\n",
    "        seed(10)\n",
    "        shuffle(self.fpaths)\n",
    "        self.targets = [fpath.split(\"/\")[-1].startswith(\"dog\") for fpath in self.fpaths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fpaths)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        f = self.fpaths[ix]\n",
    "        target = self.targets[ix]\n",
    "        im = cv2.imread(f)[:, :, ::-1]\n",
    "        im = cv2.resize(im, (224, 224))\n",
    "        im = torch.tensor(im / 255)\n",
    "        im = im.permute(2, 0, 1)\n",
    "        im = self.normalize(im)\n",
    "        return im.float().to(device), torch.tensor([target]).float().to(device)\n",
    "\n",
    "\n",
    "def get_model_vgg():\n",
    "    model = models.vgg16(weights=True)\n",
    "\n",
    "    # 冻结vgg预训练模型所有的参数\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 用自适应池化层, 压缩为[-1, 512, 1, 1], 方便后面的全连接层\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(128, 1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    return model.to(device), loss_fn, optimizer\n",
    "\n",
    "\n",
    "def get_model_resnet():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))  #\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(128, 1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    return model.to(device), loss_fn, optimizer\n",
    "\n",
    "\n",
    "def train_batch(x, y, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction, y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(x, y, model):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    is_correct = (prediction > 0.5) == y\n",
    "    return is_correct.cpu().numpy().tolist()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_loss(x, y, model, loss_fn):\n",
    "    prediction = model(x)\n",
    "    val_loss = loss_fn(prediction, y)\n",
    "    return val_loss.item()\n",
    "\n",
    "\n",
    "def get_data(train_data_dir, test_data_dir):\n",
    "    train = CatsDogsDataset(train_data_dir)\n",
    "    trn_dl = DataLoader(train, batch_size=32, shuffle=True, drop_last=True)\n",
    "    val = CatsDogsDataset(test_data_dir)\n",
    "    val_dl = DataLoader(val, batch_size=32, shuffle=True, drop_last=True)\n",
    "    return trn_dl, val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_data_dir = \"./content/training_set/training_set\"\n",
    "    test_data_dir = \"./content/test_set/test_set\"\n",
    "\n",
    "    trn_dl, val_dl = get_data(train_data_dir, test_data_dir)\n",
    "    model, loss_fn, optimizer = get_model_vgg()\n",
    "\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(5):\n",
    "        print(f\"epoch: {epoch+1}\")\n",
    "\n",
    "        train_epoch_losses, train_epoch_accuracies = [], []\n",
    "        val_epoch_accuracies = []\n",
    "        val_epoch_losses = []\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        num_batch = len(trn_dl)\n",
    "        for idx, batch in enumerate(trn_dl, 1):\n",
    "            print(f\"\\ttraining: {idx}/{num_batch}\")\n",
    "            x, y = batch\n",
    "\n",
    "            batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "            train_epoch_losses.append(batch_loss)\n",
    "\n",
    "            is_correct = accuracy(x, y, model)\n",
    "            train_epoch_accuracies.extend(is_correct)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        for idx, batch in enumerate(val_dl, 1):\n",
    "            print(f\"\\tevaluating: {idx}/{num_batch}\")\n",
    "\n",
    "            x, y = batch\n",
    "            val_is_correct = accuracy(x, y, model)\n",
    "            val_epoch_accuracies.extend(val_is_correct)\n",
    "\n",
    "            validation_loss = val_loss(x, y, model, loss_fn)\n",
    "            val_epoch_losses.append(validation_loss)\n",
    "\n",
    "        train_epoch_loss = np.mean(train_epoch_losses)\n",
    "        train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
    "        val_epoch_loss = np.mean(val_epoch_losses)\n",
    "        val_epoch_accuracy = np.mean(val_epoch_accuracies)\n",
    "\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        train_accuracies.append(train_epoch_accuracy)\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "        print(\n",
    "            f\"Train Loss: {train_epoch_loss:.4f}, Train Accuracy: {train_epoch_accuracy:.4f}\"\n",
    "        )\n",
    "        print(f\"Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_accuracy:.4f}\")\n",
    "\n",
    "    return train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies, val_accuracies = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = np.arange(5)+1\n",
    "plt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "plt.title('Training and validation accuracy with 4K data points used for training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.95,1)\n",
    "plt.gca().set_yticklabels([f'{x*100:.0f}%' for x in plt.gca().get_yticks()]) \n",
    "plt.legend()\n",
    "plt.grid('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
